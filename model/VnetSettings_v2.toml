[paths]
    [paths.PA]
    # Punta Arenas
    hourly_path = '/media/sdig/LACROS/cloudnet/data/punta-arenas/calibrated/voodoo/hourly-cn133/'
    folds_path = '/media/sdig/LACROS/cloudnet/data/punta-arenas/calibrated/voodoo/10folds-cn133/'
    categorize_path = '/media/sdig/LACROS/cloudnet/data/punta-arenas/processed-hatpro/limrad94/categorize/'

    [paths.LE]
    # Leipzig
    hourly_path = '/media/sdig/leipzig/cloudnet/calibrated/voodoo/hourly-cn133/'
    folds_path = '/media/sdig/leipzig/cloudnet/calibrated/voodoo/10folds-cn133/'
    categorize_path = '/media/sdig/leipzig/cloudnet/processed-hatpro/limrad94/categorize/'

[data_settings]

    site = 'PA'
    fn = 'XX'                       # fold number (data file) X with X in {0, 1, ..., 9, 'X'}
    shuffle = true                  # shuffle the training set
    dupe_CD = 0                     # duplicate the cloud droplet samples
    drop_data = 0.0                 # remove 0 <= X < 1. of the data
    garbage = [0, 3, 7, 8, 9, 10]   # list of classes to remove from training set

    # output classes, Cloudnet classes grouped in:
    [data_settings.groups]
        0 = [1, 5]                   # liquid droplet bearing
        1 = [2, 4, 6]                # no liquid dropets present
        #0 = [1, 3, 5, 7]            # liquid droplet bearing
        #1 = [0, 2, 4, 6, 8, 9, 10]  # no liquid dropets present

[pytorch]

    # general settings
    p = 0.0             # classification threshold p-value
    dev = 'cuda:3'      # 'cuda:X' with X in {0,1,2,3} or 'cpu'
    dy = 0.0            # subtract delta y from one-hot-endoced labels (sensitivity study)

    # training parameters
    epochs = 10
    learning_rate = 1.0e-4
    learning_rate_decay = 1.0e-1
    learning_rate_decay_step = 5
    batch_size = 512
    optimizer  = 'adam'
    dropout = 0.0

    # architectural parameters
    kernel_sizes  = [[3, 3], [3, 3], [1, 3], [1, 3], [1, 3]]
    pad_sizes     = [[1, 1], [1, 1], [0, 1], [0, 1], [0, 1]]
    stride_sizes  = [[1, 2], [1, 2], [1, 2], [2, 2], [1, 2]]
    num_filters   = [16, 32, 64, 128, 256]
    dense_layers = [128, 128, 64]

    # activation functions
    # why elu? --> https://arxiv.org/pdf/1511.07289.pdf
    hidden_activations = 'elu'    # 'relu
    output_activation = 'softmax'

    # loss function
    loss = 'crossentropy'


